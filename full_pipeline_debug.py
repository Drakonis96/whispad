#!/usr/bin/env python3
"""
Full pipeline debug
"""

import sys
import os
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from concept_graph import tokenize, extract_high_quality_terms, build_graph

# Spanish text
spanish_text = """
La computaciÃ³n en la nube ofrece infraestructura escalable para aplicaciones. La ciberseguridad 
protege los activos digitales. El internet de las cosas conecta dispositivos para generar datos.

La tecnologÃ­a blockchain proporciona libros contables seguros. La computaciÃ³n cuÃ¡ntica promete 
resolver problemas complejos. La visiÃ³n por computadora permite a las mÃ¡quinas interpretar informaciÃ³n visual.

La computaciÃ³n mÃ³vil proporciona acceso ubicuo. El comercio electrÃ³nico permite compras en lÃ­nea.
La ingenierÃ­a de software asegura el diseÃ±o sistemÃ¡tico de sistemas robustos.
"""

print("ğŸ” DEPURACIÃ“N COMPLETA DEL PIPELINE")
print("=" * 60)

print("1ï¸âƒ£ extract_high_quality_terms:")
terms = extract_high_quality_terms(spanish_text, language='spanish')
print(f"   ğŸ“Š Cantidad: {len(terms)}")
compound_terms = [t for t in terms if ' ' in t]
single_terms = [t for t in terms if ' ' not in t]
print(f"   ğŸ“ Compuestos ({len(compound_terms)}): {sorted(compound_terms)}")
print(f"   ğŸ“ Simples ({len(single_terms)}): {sorted(single_terms)}")

print()
print("2ï¸âƒ£ tokenize (max_terms=25):")
tokenized = tokenize(spanish_text, analysis_type='bridges', max_terms=25, language='spanish')
print(f"   ğŸ“Š Cantidad: {len(tokenized)}")
compound_tokenized = [t for t in tokenized if ' ' in t]
single_tokenized = [t for t in tokenized if ' ' not in t]
print(f"   ğŸ“ Compuestos ({len(compound_tokenized)}): {sorted(compound_tokenized)}")
print(f"   ğŸ“ Simples ({len(single_tokenized)}): {sorted(single_tokenized)}")

print()
print("3ï¸âƒ£ build_graph:")
graph_result = build_graph(spanish_text, analysis_type='bridges', language='spanish', max_terms=25)
print(f"   ğŸ“Š Cantidad de nodos: {len(graph_result['nodes'])}")
node_labels = [node.get('label', '') for node in graph_result['nodes']]
compound_nodes = [l for l in node_labels if ' ' in l]
single_nodes = [l for l in node_labels if ' ' not in l]
print(f"   ğŸ“ Compuestos ({len(compound_nodes)}): {sorted(compound_nodes)}")
print(f"   ğŸ“ Simples ({len(single_nodes)}): {sorted(single_nodes)}")

print()
print("4ï¸âƒ£ AnÃ¡lisis de pÃ©rdidas:")
lost_compounds = set(compound_terms) - set(compound_nodes)
if lost_compounds:
    print(f"   âŒ Compuestos perdidos: {sorted(lost_compounds)}")
else:
    print("   âœ… No se perdieron compuestos")

expected_compounds = ['computacion nube', 'internet cosas', 'tecnologia blockchain', 'computacion cuantica', 'vision computadora', 'computacion movil', 'comercio electronico', 'ingenieria software']
found_expected = [c for c in expected_compounds if c in node_labels]
print(f"   âœ… Compuestos esperados encontrados: {found_expected}")
missing_expected = [c for c in expected_compounds if c not in node_labels]
print(f"   âŒ Compuestos esperados faltantes: {missing_expected}")

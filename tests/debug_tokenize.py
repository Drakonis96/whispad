#!/usr/bin/env python3
"""
Debug tokenize function
"""

import sys
import os
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from concept_graph import tokenize, extract_high_quality_terms

# Spanish text
spanish_text = """
La computaciÃ³n en la nube ofrece infraestructura escalable para aplicaciones. La ciberseguridad 
protege los activos digitales. El internet de las cosas conecta dispositivos para generar datos.

La tecnologÃ­a blockchain proporciona libros contables seguros.
"""

print("ğŸ” DEPURACIÃ“N DE LA FUNCIÃ“N TOKENIZE")
print("=" * 60)

print("1ï¸âƒ£ TÃ©rminos extraÃ­dos por extract_high_quality_terms:")
terms = extract_high_quality_terms(spanish_text, language='spanish')
print(f"   ğŸ“Š Cantidad: {len(terms)}")
print(f"   ğŸ“ TÃ©rminos: {sorted(terms)}")

print()
print("2ï¸âƒ£ TÃ©rminos procesados por tokenize:")
tokenized_terms = tokenize(spanish_text, analysis_type='bridges', language='spanish')
print(f"   ğŸ“Š Cantidad: {len(tokenized_terms)}")
print(f"   ğŸ“ TÃ©rminos: {sorted(tokenized_terms)}")

print()
print("3ï¸âƒ£ ComparaciÃ³n:")
missing_in_tokenize = set(terms) - set(tokenized_terms)
if missing_in_tokenize:
    print(f"   âŒ Perdidos en tokenize: {sorted(missing_in_tokenize)}")
else:
    print("   âœ… No se perdieron tÃ©rminos en tokenize")

added_in_tokenize = set(tokenized_terms) - set(terms)
if added_in_tokenize:
    print(f"   â• AÃ±adidos en tokenize: {sorted(added_in_tokenize)}")
